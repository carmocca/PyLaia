#!/usr/bin/env python3
import argparse
import os

import torch

import laia.common.logging as log
import laia.data.transforms as transforms
from laia.common.arguments import add_argument, args, add_defaults
from laia.common.arguments_types import str2bool
from laia.common.loader import ModelLoader, CheckpointLoader
from laia.data import ImageDataLoader, ImageFromListDataset
from laia.decoders import CTCGreedyDecoder
from laia.engine.feeders import ImageFeeder, ItemFeeder
from laia.experiments import Experiment
from laia.utils import SymbolsTable
from laia.utils.segmentation import word_segmentation


def main(args):
    syms = SymbolsTable(args.syms)

    device = torch.device("cuda:{}".format(args.gpu - 1) if args.gpu else "cpu")

    model = ModelLoader(
        args.train_path, filename=args.model_filename, device=device
    ).load()
    if model is None:
        log.error("Could not find the model")
        exit(1)
    state = CheckpointLoader(device=device).load_by(
        os.path.join(args.train_path, args.checkpoint)
    )
    model.load_state_dict(
        state if args.source == "model" else Experiment.get_model_state_dict(state)
    )
    model = model.to(device)
    model.eval()

    dataset = ImageFromListDataset(
        args.img_list,
        img_dirs=args.img_dirs,
        img_transform=transforms.vision.ToImageTensor(
            mode=args.color_mode, invert=True
        ),
    )
    dataset_loader = ImageDataLoader(
        dataset=dataset,
        image_channels=len(args.color_mode),
        batch_size=args.batch_size,
        num_workers=8,
    )
    batch_input_fn = ImageFeeder(device=device, parent_feeder=ItemFeeder("img"))

    decoder = CTCGreedyDecoder()
    for batch in dataset_loader:
        batch_input = batch_input_fn(batch)
        batch_output = model(batch_input)
        decoder(batch_output, segmentation=bool(args.print_segmentation))
        for i, (img_id, out) in enumerate(zip(batch["id"], decoder.output)):
            if args.use_letters or bool(args.print_segmentation):
                out = [str(syms[val]) for val in out]
            if bool(args.print_segmentation):
                w = batch_input.sizes[i, 1]
                max_pos = decoder.segmentation[i][-1]
                scaled = [(x * w // max_pos).item() for x in decoder.segmentation[i]]
                out = [(out[i], scaled[i], scaled[i + 1]) for i in range(len(out))]
                if args.print_segmentation == "word":
                    out = word_segmentation(out, args.input_space)
            else:
                if args.convert_spaces:
                    out = [
                        args.output_space if sym == args.input_space else sym
                        for sym in out
                    ]
                if args.join_str is not None:
                    out = args.join_str.join(str(x) for x in out)
            print(
                "{}{}{}".format(img_id, args.separator, out)
                if args.print_img_ids
                else out
            )


if __name__ == "__main__":
    add_defaults(
        "batch_size", "gpu", "train_path", "color_mode", logging_level="WARNING"
    )
    add_argument(
        "syms",
        type=argparse.FileType("r"),
        help="Symbols table mapping from strings to integers",
    )
    add_argument(
        "img_dirs",
        type=str,
        nargs="*",
        help="Directory containing word images. Optional if img_list contains whole paths",
    )
    add_argument(
        "img_list",
        type=argparse.FileType("r"),
        help="File containing images to decode. Doesn't require the extension",
    )
    add_argument(
        "--model_filename", type=str, default="model", help="File name of the model"
    )
    add_argument(
        "--checkpoint",
        type=str,
        default="experiment.ckpt.lowest-valid-cer*",
        help="Name of the model checkpoint to use, can be a glob pattern",
    )
    add_argument(
        "--source",
        type=str,
        default="experiment",
        choices=["experiment", "model"],
        help="Type of class which generated the checkpoint",
    )
    add_argument(
        "--print_img_ids",
        type=str2bool,
        nargs="?",
        const=True,
        default=True,
        help="Print output with the associated image id",
    )
    add_argument(
        "--separator",
        type=str,
        default=" ",
        help="Use this string as the separator between the ids and the output",
    )
    add_argument("--join_str", type=str, help="Join the output using this")
    add_argument(
        "--use_letters", action="store_true", help="Print the output with letters"
    )
    add_argument(
        "--convert_spaces", action="store_true", help="Whether or not to convert spaces"
    )
    add_argument(
        "--input_space",
        type=str,
        default="<space>",
        help="Input space symbol to replace",
    )
    add_argument(
        "--output_space", type=str, default="", help="Output space symbol",
    )
    add_argument(
        "--print_segmentation",
        type=str,
        default=None,
        choices=["char", "word"],
        help="Print output with the corresponding segmentation",
    )
    main(args())
